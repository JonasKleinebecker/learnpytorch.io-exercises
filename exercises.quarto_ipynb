{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"PyTorch Exercises\"\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "## Imports "
      ],
      "id": "a816b59c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from ml_utils import plot_decision_boundary"
      ],
      "id": "a8d51709",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch Exercises 00 pytorch fundamentals\n",
        "https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises"
      ],
      "id": "8cc15715"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(1234)\n",
        "x = torch.randn(7 ,7)\n",
        "y = torch.randn(1 ,7)\n",
        "z = torch.matmul(x, y.T)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)\n",
        "gpu_1 = torch.randn(2 ,3).to(device)\n",
        "torch.manual_seed(42)\n",
        "gpu_2 = torch.randn(2 ,3).to(device)\n",
        "\n",
        "gpu_3 = torch.matmul(gpu_1, gpu_2.T)\n",
        "\n",
        "print(gpu_3.max())\n",
        "print(gpu_3.argmax())\n",
        "print(gpu_3.reshape(4)[3])\n",
        "\n",
        "print(gpu_3.argmin())\n",
        "\n",
        "torch.manual_seed(7)\n",
        "original_tensor = torch.randn(1, 1, 1, 10)\n",
        "squeezed_tensor = original_tensor.squeeze()\n",
        "print(original_tensor.shape, original_tensor)\n",
        "print(squeezed_tensor.shape, squeezed_tensor)"
      ],
      "id": "175aa8eb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch Exercises 01 pytorch Workflow fundamentals"
      ],
      "id": "9a33a941"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "x = torch.arange(0, 1, 0.0025, dtype=torch.float32).unsqueeze(dim=1).to(device)\n",
        "print(x.shape)\n",
        "target_bias = 0.9\n",
        "target_weight = 0.3\n",
        "y = target_bias + target_weight * x\n",
        "\n",
        "training_split = int(0.8 * len(x))\n",
        "\n",
        "x_train, y_train = x[:training_split], y[:training_split]\n",
        "x_val, y_val = x[training_split:], y[training_split:]\n",
        "\n",
        "plt.scatter(x_train.cpu(), y_train.cpu(), label=\"train\", color=\"blue\")\n",
        "plt.scatter(x_val.cpu(), y_val.cpu(), label=\"validation\", color=\"orange\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.randn(1, device=device))\n",
        "    self.bias = nn.Parameter(torch.randn(1, device=device))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.weight * x + self.bias\n",
        "\n",
        "torch.manual_seed(2)\n",
        "model_0 = LinearRegression()\n",
        "\n",
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(model_0.parameters(), lr=0.02)\n",
        "\n",
        "nun_epochs = 300 \n",
        "\n",
        "epochs = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(nun_epochs):\n",
        "  model_0.train()\n",
        "  \n",
        "  y_logits = model_0(x_train)\n",
        "  \n",
        "  loss = loss_fn(y_logits, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "  \n",
        "  model_0.eval()\n",
        "  \n",
        "  with torch.inference_mode():\n",
        "    y_val_logits = model_0(x_val)\n",
        "    val_loss = loss_fn(y_val_logits, y_val)\n",
        "  \n",
        "  epochs.append(epoch)\n",
        "  train_losses.append(loss.item())\n",
        "  val_losses.append(val_loss.item())\n",
        "  \n",
        "  if epoch % 20 == 0:\n",
        "    print(f\"epoch {epoch+1}: train loss {loss}, val loss {val_loss}\")\n",
        "\n",
        "plt.plot(epochs, train_losses, label=\"train\")\n",
        "plt.plot(epochs, val_losses, label=\"val\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  y_logits = model_0(x_val)\n",
        "\n",
        "plt.scatter(x_train.detach().cpu(), y_train.detach().cpu(), label=\"train\", color=\"green\")\n",
        "plt.scatter(x_val.cpu(), y_val.cpu(), label=\"validation\", color=\"orange\")\n",
        "plt.scatter(x_val.cpu(), y_logits.cpu(), label=\"predictions\", color=\"blue\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n",
        "\n",
        "torch.save(model_0.state_dict(), \"model_0.pth\")\n",
        "\n",
        "model_0_loaded = LinearRegression()\n",
        "model_0_loaded.load_state_dict(torch.load(\"model_0.pth\"))\n",
        "with torch.inference_mode():\n",
        "  y_logits = model_0_loaded(x_val)\n",
        "\n",
        "plt.scatter(x_train.detach().cpu(), y_train.detach().cpu(), label=\"train\", color=\"green\")\n",
        "plt.scatter(x_val.cpu(), y_val.cpu(), label=\"validation\", color=\"orange\")\n",
        "plt.scatter(x_val.cpu(), y_logits.cpu(), label=\"predictions\", color=\"blue\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()"
      ],
      "id": "45021202",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch Exercises 02 pytorch classification"
      ],
      "id": "0215dbf9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "NUM_SAMPLES = 1000\n",
        "RANDOM_SEED = 42\n",
        "X, y = make_moons(NUM_SAMPLES, noise=0.2, random_state=RANDOM_SEED)\n",
        "\n",
        "X = torch.from_numpy(X).float().to(device)\n",
        "y = torch.from_numpy(y).float().to(device)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X_train.cpu()[:, 0], X_train.cpu()[:, 1], c=y_train.cpu(), cmap=plt.cm.RdYlBu)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_test.cpu()[:, 0], X_test.cpu()[:, 1], c=y_test.cpu(), cmap=plt.cm.RdYlBu)\n",
        "plt.show()\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super().__init__()\n",
        "    self.sequential = nn.Sequential(\n",
        "      nn.Linear(in_features, 64),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(64, 64),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(64, out_features),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.sequential(x).squeeze(-1)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "model1 = LogisticRegression(2, 1).to(device)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=0.01)\n",
        "\n",
        "NUM_EPOCHS = 10000\n",
        "\n",
        "epochs = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accs = []\n",
        "val_accs = []\n",
        " \n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  model1.train()\n",
        "  \n",
        "  y_logits = model1(X_train.squeeze())\n",
        "  y_preds = torch.round(torch.sigmoid(y_logits))\n",
        "  \n",
        "  train_acc = accuracy_score(y_train.detach().cpu(), y_preds.detach().cpu())\n",
        "  train_accs.append(train_acc)\n",
        "  \n",
        "  loss = loss_fn(y_logits, y_train)\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  loss.backward()\n",
        "  \n",
        "  optimizer.step()\n",
        "  \n",
        "  model1.eval()\n",
        "  \n",
        "  with torch.inference_mode():\n",
        "    y_val_logits = model1(X_test)\n",
        "    y_preds = torch.round(torch.sigmoid(y_val_logits))\n",
        "    val_acc = accuracy_score(y_test.detach().cpu(), y_preds.detach().cpu())\n",
        "    val_accs.append(val_acc)\n",
        "    val_loss = loss_fn(y_val_logits, y_test)\n",
        "  \n",
        "  epochs.append(epoch)\n",
        "  train_losses.append(loss.item())\n",
        "  val_losses.append(val_loss.item())\n",
        "  \n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"epoch {epoch+1}: train loss {loss} | train acc {train_acc} |  val loss {val_loss} | val acc {val_acc}\")\n",
        "\n",
        "plot_decision_boundary(model1, X_train, y_train)\n",
        "plt.show()\n",
        "\n",
        "def tanh(x):\n",
        "  return (torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x))\n",
        "\n",
        "# Multiclass classification for spiral dataset from CS231n\n",
        "POINTS_PER_CLASS = 100\n",
        "DIMENSIONALITY = 2\n",
        "NUM_CLASSES = 3\n",
        "X = torch.zeros(POINTS_PER_CLASS * NUM_CLASSES, DIMENSIONALITY)\n",
        "y = torch.zeros(POINTS_PER_CLASS * NUM_CLASSES, dtype=torch.long)\n",
        "\n",
        "for class_number in range(NUM_CLASSES):\n",
        "  ix = range(POINTS_PER_CLASS * class_number, POINTS_PER_CLASS * (class_number + 1))\n",
        "  r = torch.linspace(0.0, 1, POINTS_PER_CLASS)\n",
        "  t = torch.linspace(class_number * 4, (class_number + 1) * 4, POINTS_PER_CLASS) + torch.randn(POINTS_PER_CLASS) * 0.2\n",
        "  X[ix] = torch.stack([r * torch.cos(t), r * torch.sin(t)], dim=1)\n",
        "  y[ix] = class_number\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
        "plt.show()\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "model2 = LogisticRegression(DIMENSIONALITY, NUM_CLASSES).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
        "\n",
        "X = X.to(device)\n",
        "y = y.to(device)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "NUM_EPOCHS = 1000\n",
        "\n",
        "epochs = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  model2.train()\n",
        "  \n",
        "  y_logits = model2(X_train)\n",
        "  y_preds = torch.argmax(y_logits, dim=1)\n",
        "  \n",
        "  train_acc = accuracy_score(y_train.detach().cpu(), y_preds.detach().cpu())\n",
        "  train_accs.append(train_acc)\n",
        "  \n",
        "  loss = loss_fn(y_logits, y_train)\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  loss.backward()\n",
        "  \n",
        "  optimizer.step()\n",
        "  \n",
        "  model2.eval()\n",
        "  \n",
        "  with torch.inference_mode():\n",
        "    y_val_logits = model2(X_test)\n",
        "    y_val_preds = torch.argmax(y_val_logits, dim=1)\n",
        "    val_acc = accuracy_score(y_test.detach().cpu(), y_val_preds.detach().cpu())\n",
        "    val_accs.append(val_acc)\n",
        "    val_loss = loss_fn(y_val_logits, y_test)\n",
        "  \n",
        "  epochs.append(epoch)\n",
        "  train_losses.append(loss.item())\n",
        "  val_losses.append(val_loss.item())\n",
        "  \n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"epoch {epoch+1}: train loss {loss} | train acc {train_acc} |  val loss {val_loss} | val acc {val_acc}\")\n",
        "\n",
        "plot_decision_boundary(model2, X_train, y_train)\n",
        "plt.show()"
      ],
      "id": "87190fec",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/jonas/venvs/ml_env/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}